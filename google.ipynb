{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the training set\n",
    "total=pd.read_csv('GOOGL.csv')\n",
    "total_set=total.iloc[:, 1:2].values\n",
    "#dataset_train = pd.read_csv('g2014-2018.csv')\n",
    "#training_set = dataset_train.iloc[:, 1:2].values\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "total_set_scaled = sc.fit_transform(total_set)\n",
    "\n",
    "total_set_scaled=pd.DataFrame(total_set_scaled)\n",
    "\n",
    "training_set_scaled=total_set_scaled.iloc[:3616,:]\n",
    "real_stock_price=total_set_scaled.iloc[3617:,:]\n",
    "\n",
    "#training_set_scaled.index = range(1, 1258)\n",
    "real_stock_price.index = range(1,82)\n",
    "\n",
    "training_set_scaled=training_set_scaled.values\n",
    "real_stock_price=real_stock_price.values\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 3616):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "# Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainl = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "regressorl = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressorl.add(LSTM(units = 350, return_sequences = True, input_shape = (X_trainl.shape[1], 1)))\n",
    "regressorl.add(Dropout(0.4))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressorl.add(LSTM(units = 100))\n",
    "regressorl.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressorl.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainf = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "regressorf = Sequential()\n",
    "\n",
    "regressorf.add(Dense(5000, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "\n",
    "regressorf.add(Dense(3000, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "regressorf.add(Dropout(0.3))\n",
    "\n",
    "regressorf.add(Dense(1500, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "regressorf.add(Dropout(0.3))\n",
    "\n",
    "regressorf.add(Dense(1350, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "regressorf.add(Dropout(0.3))\n",
    "\n",
    "regressorf.add(Dense(1250, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "regressorf.add(Dropout(0.3))\n",
    "\n",
    "regressorf.add(Dense(800, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "regressorf.add(Dropout(0.3))\n",
    "\n",
    "regressorf.add(Dense(60, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "regressorf.add(Dropout(0.3))\n",
    "\n",
    "regressorf.add(Dense(10, input_dim=60,activity_regularizer=regularizers.l2(0.01)))\n",
    "regressorf.add(BatchNormalization())\n",
    "regressorf.add(Activation(\"relu\"))\n",
    "regressorf.add(Dropout(0.3))\n",
    "\n",
    "regressorf.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainc = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import Dense,Activation, Dropout,Convolution1D,MaxPooling1D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import *\n",
    "\n",
    "regressorc = Sequential()\n",
    "\n",
    "regressorc.add(Convolution1D(filters=512,kernel_size=2,kernel_initializer='VarianceScaling',activation='relu',input_shape=(60, 1)))\n",
    "regressorc.add(Convolution1D(filters=256,kernel_size=2,kernel_initializer='VarianceScaling',activation='relu',input_shape=(60, 1)))\n",
    "regressorc.add(Convolution1D(filters=128,kernel_size=1,kernel_initializer='VarianceScaling',activation='relu',input_shape=(60, 1)))\n",
    "\n",
    "regressorc.add(Dropout(0.3))\n",
    "regressorc.add(MaxPooling1D(pool_size=3, stride=3))\n",
    "\n",
    "regressorc.add(Flatten())\n",
    "\n",
    "regressorc.add(Dense(7247, activation='relu'))\n",
    "regressorc.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressorl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regressorf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressorc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the ^GSPCval.csv\n",
    "#dataset_val = pd.read_csv('g2014-2018val.csv')\n",
    "#val_set = dataset_val.iloc[:, 1:2].values\n",
    "#val_set_scaled = sc.fit_transform(val_set)\n",
    "\n",
    "# Importing the training set\n",
    "val=pd.read_csv('GOOGLM.csv')\n",
    "val_set=val.iloc[:, 1:2].values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "val_set_scaled = sc.fit_transform(val_set)\n",
    "val_set_scaled=pd.DataFrame(val_set_scaled)\n",
    "\n",
    "val_set_scaled=val_set_scaled.iloc[:750,:]\n",
    "\n",
    "#val_set_scaled.index = range(1,261)\n",
    "val_set_scaled=val_set_scaled.values\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for i in range(60, 750):\n",
    "    # Creates the 60 timesteps of each value. E.g. row 1 = 0 -> 59, row 2 = 1 -> 60\n",
    "    X_val.append(val_set_scaled[i-60:i])\n",
    "    # Contains the next value after the 60 timesteps. E.g. row 1 = last value of row 2, row 2 = last value of row 3\n",
    "    # This is used to predict the next value (future value)\n",
    "    y_val.append(val_set_scaled[i])\n",
    "# Convert to numpy array to be accepted in our RNN\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_vall = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressorl.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressorl_history=regressorl.fit(X_trainl, y_train, epochs =50, batch_size = 128,validation_data=(X_vall, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valf=np.reshape(X_val, (X_val.shape[0], X_val.shape[1]))\n",
    "# Compiling the NN\n",
    "regressorf.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "regressorf_history=regressorf.fit(X_trainf, y_train, epochs =100, batch_size = 128,validation_data=(X_valf, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valc = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "opt = Adam(lr=0.001)\n",
    "regressorc.compile(optimizer=opt,loss='mse')\n",
    "regressorc_history=regressorc.fit(X_trainc, y_train, batch_size=128, epochs=100,validation_data=(X_valc, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "# Getting the real stock price of 2017\n",
    "#dataset_test = pd.read_csv('g2019.csv')\n",
    "#real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "#dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "total_set=pd.DataFrame(total_set)\n",
    "real_stock_price=pd.DataFrame(real_stock_price)\n",
    "inputs = total_set[len(total_set) - len(real_stock_price) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(60, 141):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "    y_test.append(inputs[i])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_testl = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "scorel = regressorl.evaluate(X_testl, y_test)\n",
    "print('lstm loss:', scorel)\n",
    "\n",
    "X_testf = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]))\n",
    "scoref = regressorf.evaluate(X_testf, y_test)\n",
    "print('fnn loss:', scoref)\n",
    "\n",
    "X_testc = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "scorec = regressorc.evaluate(X_testc, y_test)\n",
    "print('cnn loss:', scorec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price=sc.inverse_transform(real_stock_price)\n",
    "\n",
    "\n",
    "predicted_stock_pricel = regressorl.predict(X_testl)\n",
    "predicted_stock_pricel = sc.inverse_transform(predicted_stock_pricel)\n",
    "\n",
    "predicted_stock_pricef = regressorf.predict(X_testf)\n",
    "predicted_stock_pricef = sc.inverse_transform(predicted_stock_pricef)\n",
    "\n",
    "predicted_stock_pricec = regressorc.predict(X_testc)\n",
    "predicted_stock_pricec = sc.inverse_transform(predicted_stock_pricec)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'yellow', label = 'Real ')\n",
    "plt.plot(predicted_stock_pricel, color = 'green', label = 'lstm ')\n",
    "plt.plot(predicted_stock_pricec, color = 'blue', label = 'cnn')\n",
    "plt.plot(predicted_stock_pricef, color = 'red', label = 'fully')\n",
    "\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend( loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error #均方误差\n",
    "from sklearn.metrics import mean_absolute_error #平方绝对误差\n",
    "from sklearn.metrics import r2_score#R square\n",
    "\n",
    "print('lstm mse:',mean_squared_error(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricel))\n",
    "      ,'lstm mae:',mean_absolute_error(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricel))\n",
    "      ,'lstm r2:',r2_score(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricel)))\n",
    "\n",
    "print('fnn mse:',mean_squared_error(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricef))\n",
    "      ,'fnn mae:',mean_absolute_error(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricef))\n",
    "      ,'fnn r2:',r2_score(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricef)))\n",
    "\n",
    "print('cnn mse:',mean_squared_error(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricec))\n",
    "      ,'cnn mae:',mean_absolute_error(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricec))\n",
    "      ,'cnn r2:',r2_score(sc.fit_transform(y_test),sc.fit_transform(predicted_stock_pricec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
